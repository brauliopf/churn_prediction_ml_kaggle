{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "Pickle is a built-in Python module used for serializing and deserializing Python objects.\n",
        "pickle can be used to save trained models to disk. Enabling to save your trained model and load it later without having to retrain it every time you want to use it.\n",
        "'''\n",
        "\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = pd.read_csv('./data/churn.csv')\n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup environment\n",
        "sns.set_style(style=\"whitegrid\")\n",
        "\n",
        "# Distribution of churns (exited)\n",
        "sns.countplot(data=data, x=\"Exited\")\n",
        "plt.title(\"Distribution of Churn\")\n",
        "plt.show()\n",
        "\n",
        "# Histogram of custoemr ages\n",
        "sns.histplot(data=data, x=\"Age\", kde=True)\n",
        "plt.title(\"Age Distribution\")\n",
        "plt.show()\n",
        "\n",
        "# Credit Score by Age\n",
        "sns.scatterplot(data=data, y=\"Age\", x=\"CreditScore\", hue=\"Exited\")\n",
        "plt.title(\"Credit Score by Age\")\n",
        "plt.show()\n",
        "\n",
        "# Distribution Balance by churn\n",
        "sns.boxplot(data=data, x=\"Exited\", y=\"Balance\")\n",
        "plt.title(\"Distribution Balance by Churn\")\n",
        "plt.show()\n",
        "\n",
        "# Distribution of credit score by churn\n",
        "sns.boxplot(data=data, x=\"Exited\", y=\"CreditScore\")\n",
        "plt.title(\"Distribution of Credit Score by Churn\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Auxiliar Functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_object(object, filename, directory):\n",
        "  try:\n",
        "    with open(os.path.join(directory, filename), 'wb') as file:\n",
        "      pickle.dump(object, file)\n",
        "  except Exception as e:\n",
        "    print(f\"Error saving object: {e}\")\n",
        "  return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Select features and handle NA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# separate features and target\n",
        "features = data.drop('Exited', axis=1)\n",
        "target = data['Exited']\n",
        "\n",
        "## feature selection\n",
        "# remove unnecessary columns\n",
        "features = features.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis=1)\n",
        "# handle missing values\n",
        "print('Shape before dropna:', features.shape)\n",
        "features.dropna(inplace=True)\n",
        "print('Shape after dropna:', features.shape)\n",
        "\n",
        "# handle categorical features: one-hot encoding\n",
        "features = pd.get_dummies(data=features, columns=[\"Geography\", \"Gender\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SPLIT\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SCALE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)\n",
        "\n",
        "# save scaler\n",
        "save_object(scaler, 'scaler.pkl', 'models')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**EXAMPLE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TRAIN\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_model = LogisticRegression(random_state=42)\n",
        "lr_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PREDICT\n",
        "lr_predictions = lr_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EVALUATE\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "print('Accuracy Score:', accuracy_score(y_test, lr_predictions))\n",
        "print('Confusion Matrix:')\n",
        "confusion_matrix(y_true=y_test, y_pred=lr_predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**COMPARE MODELS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_and_evaluate(model, X_train, X_test, y_train, y_test, filename='model.pkl', directory=None):\n",
        "  # fit\n",
        "  model.fit(X_train, y_train)\n",
        "  # predict\n",
        "  y_pred = model.predict(X_test)\n",
        "  # get accuracy\n",
        "  accuracy = accuracy_score(y_test,y_pred)\n",
        "  # report accuracy\n",
        "  print(f'{model.__class__.__name__} Accuracy: {accuracy:.4f}')\n",
        "  # create classification report\n",
        "  print(classification_report(y_test, y_pred))\n",
        "\n",
        "  # save model to file if directory provided\n",
        "  if directory:\n",
        "    save_object(model, filename, directory)\n",
        "\n",
        "  # pretty layout\n",
        "  print('*' * 50)\n",
        "\n",
        "  return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lrg_model = LogisticRegression(random_state=42)\n",
        "train_and_evaluate(lrg_model, X_train, X_test, y_train, y_test, 'lgr_model.pkl', './models')\n",
        "\n",
        "xgb_model = xgb.XGBClassifier(random_state=42)\n",
        "train_and_evaluate(xgb_model, X_train, X_test, y_train, y_test, 'xgb_model.pkl', './models')\n",
        "\n",
        "rfc_model = RandomForestClassifier(random_state=42)\n",
        "train_and_evaluate(rfc_model, X_train, X_test, y_train, y_test, 'rfc_model.pkl', './models')\n",
        "\n",
        "tre_model = DecisionTreeClassifier(random_state=42)\n",
        "train_and_evaluate(tre_model, X_train, X_test, y_train, y_test, 'tre_model.pkl', './models')\n",
        "\n",
        "gnb_model = GaussianNB()\n",
        "train_and_evaluate(gnb_model, X_train, X_test, y_train, y_test, 'gnb_model.pkl', './models')\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "train_and_evaluate(knn_model, X_train, X_test, y_train, y_test, 'knn_model.pkl', './models')\n",
        "\n",
        "svm_model = SVC(random_state=42)\n",
        "train_and_evaluate(svm_model, X_train, X_test, y_train, y_test, 'svm_model.pkl', './models')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observation: XGBoost does not have the highest accuracy, but it has the highest recall of the churners."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get feature importance\n",
        "feature_importances = xgb_model.feature_importances_\n",
        "feature_names = features.columns\n",
        "\n",
        "feature_importances_df = pd.DataFrame(zip(feature_names, feature_importances))\n",
        "feature_importances_df.columns = ['feature', 'importance']\n",
        "\n",
        "feature_importances_df = feature_importances_df.sort_values('importance', ascending=False)\n",
        "\n",
        "# plot bar chart\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(feature_importances_df['feature'], feature_importances_df['importance'])\n",
        "\n",
        "# configure chart\n",
        "plt.xticks(rotation=30)\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Improve Model Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "## CREATE FEATURES\n",
        "# CLV = balance * salary / 100000\n",
        "features['CLV'] = features['Balance'] * features['EstimatedSalary'] / 100000\n",
        "# tenure / age\n",
        "features['TenureByAge'] = features['Tenure'] / features['Age']\n",
        "# age group -> create bins 0,30,45,60,100\n",
        "if('AgeGroup_Adult' not in features.columns):\n",
        "  features['AgeGroup'] = pd.cut(features['Age'], [0, 30, 45, 60, 100], labels=['Young', 'Adult', 'Senior', 'Elderly'])\n",
        "  features = pd.get_dummies(features, ['AgeGroup'], drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SPLIT\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# SCALE\n",
        "scaler_feate = StandardScaler()\n",
        "X_train = scaler_feate.fit_transform(X_train)\n",
        "X_test = scaler_feate.fit_transform(X_test)\n",
        "\n",
        "save_object(scaler_feate, 'scaler_feate.pkl', 'models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Use engineered features with XGB model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CREATE MODEL\n",
        "xgb_model_feate = xgb.XGBClassifier(random_state=42,\n",
        "                                    eta=0.6, \n",
        "                                    max_depth=6)\n",
        "\n",
        "# EVALUATE\n",
        "train_and_evaluate(xgb_model_feate, X_train, X_test, y_train, y_test, 'xgb_model_feate.pkl', './models')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "\n",
        "X_resampled, y_resampled, = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "train_and_evaluate(xgb_model_feate, X_resampled, X_test, y_resampled, y_test, 'xgb_smote.pkl', './models')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ensemble + SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "  estimators=[('xgb',xgb.XGBClassifier(random_state=42,\n",
        "                                    eta=0.6, \n",
        "                                    max_depth=6)),\n",
        "              ('rfc',RandomForestClassifier(random_state=42)),\n",
        "              ('svm',SVC(random_state=42, probability=True))],\n",
        "  voting='soft' # weight predictions by accuracy \n",
        ")\n",
        "\n",
        "train_and_evaluate(voting_clf, X_resampled, X_test, y_resampled, y_test, 'xgb_ensemble_soft.pkl', './models')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "voting_clf_hard = VotingClassifier(\n",
        "  estimators=[('xgb',xgb.XGBClassifier(random_state=42,\n",
        "                                    eta=0.6, \n",
        "                                    max_depth=6)),\n",
        "              ('rfc',RandomForestClassifier(random_state=42)),\n",
        "              ('svm',SVC(random_state=42, probability=True))],\n",
        "  voting='hard' # simple majority vote of models\n",
        ")\n",
        "\n",
        "train_and_evaluate(voting_clf_hard, X_resampled, X_test, y_resampled, y_test, 'xgb_ensemble_hard.pkl', './models')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
